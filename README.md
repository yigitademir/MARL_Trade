# Multi-Agent PPO Trading Framework
**Author:** YiÄŸit Ali Demir  
**Program:** MSc Applied Information & Data Science (HSLU)  
**Thesis Topic:** Multi-Agent PPO Trading Across Multiple Timeframes

---

## ðŸ“Œ Overview

This repository contains a complete **multi-agent reinforcement learning (MARL)** trading system built around PPO agents trained on multiple timeframes (5m, 15m, 1h, 4h).  
The goal of the thesis project is:

- Train independent agents for each timeframe  
- Coordinate their predictions via a multi-agent decision module  
- Backtest the combined policy  
- Provide a foundation for live algorithmic trading with risk management  

The system is modular, maintainable, and structured for academic reproducibility.

---

## ðŸ“‚ Repository Structure

```
MARL_Trade/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ BTCUSDT_*.parquet
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ BTCUSDT_*_features.parquet
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ thesis_notes/
â”‚   â””â”€â”€ diagrams/
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ single_agent/
â”‚   â”‚   â”œâ”€â”€ results.csv
â”‚   â”‚   â””â”€â”€ tensorboard/
â”‚   â””â”€â”€ multi_agent/
â”‚       â”œâ”€â”€ backtests/
â”‚       â”œâ”€â”€ equity/
â”‚       â””â”€â”€ trades/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ single_agents/
â”‚   â””â”€â”€ multi_agent/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ train_single_agent.py
â”‚   â”‚   â””â”€â”€ train_all_timeframes.py
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â””â”€â”€ trading_env.py
â”‚   â”œâ”€â”€ multi_agent/
â”‚   â”‚   â”œâ”€â”€ coordinator.py
â”‚   â”‚   â””â”€â”€ backtester.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_fetcher.py
â”‚       â”œâ”€â”€ features.py
â”‚       â””â”€â”€ data_checker.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_envshapes.py
â”‚   â””â”€â”€ multiagent_test.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ðŸ§  System Architecture (High-Level)

```
     DATA PIPELINE
 (fetch â†’ clean â†’ features)
             â”‚
             â–¼
   SINGLE-AGENT TRAINING
  PPO_5m, PPO_15m, PPO_1h, PPO_4h
             â”‚
             â–¼
 MULTI-AGENT COORDINATOR
 (majority vote â†’ final action)
             â”‚
             â–¼
     BACKTEST ENGINE
```

---

## ðŸ§ª Testing

Before any training or backtesting:

```
python -m tests.test_envshapes
```

This verifies:

- Observation shapes  
- Feature integrity  
- Environment consistency across timeframes  

---

## ðŸš€ Training PPO Agents (All Timeframes)

```
python src/agents/train_all_timeframes.py \
    --symbol BTCUSDT \
    --timeframes 5m,15m,1h,4h \
    --total_timesteps 100000
```

Results saved under:

```
logs/single_agent/results.csv
```

Trained models saved under:

```
models/single_agents/
```

---

## ðŸ“Š Multi-Agent Backtest

```
python -m src.multi_agent.multiagent_test
```

Outputs:

- `multi_agent_equity_curve.csv`
- `multi_agent_trades.csv`
- Console summary statistics

---

## ðŸ“„ Planned Extensions

- Full MARL (parameter sharing or central critic)
- Market regime classifier agent
- ATR-based trailing stops
- Position sizing agent
- Hyperparameter sweeps  
- Live trading connector  
- Risk management engine (SL/TP, volatility filters)

---

## ðŸ“š License

This project is created as part of a Master's thesis at **HSLU**.  
Use permitted for academic and research purposes.